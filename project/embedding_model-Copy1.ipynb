{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50a03e98-c142-47fd-81a4-f107c3ecd69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from transformers import AutoTokenizer, EsmModel\n",
    "import time\n",
    "import lightning as L\n",
    "import os\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import sklearn.metrics as skmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee2c089e-4958-484c-9189-72168e49fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtEmbeddingDataset(Dataset):\n",
    "    def __init__(self, tensor_folder, csv_file):\n",
    "        self.tensor_folder = tensor_folder\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        #self.df = self.df[self.df.mut_type != 'wt'].reset_index(drop=True)\n",
    "        self.labels = torch.tensor(self.df['ddG_ML'].values)\n",
    "        self.ids = self.df['name'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load embedding from .pt file\n",
    "        tensor_path = os.path.join(self.tensor_folder, self.ids[idx] + '.pt')\n",
    "        embedding = torch.load(tensor_path)['mean_representations'][6] \n",
    "        label = self.labels[idx]\n",
    "        return embedding, label.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a09dd400-37a5-46ca-8b79-40af9677a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ProtEmbeddingDataset(\n",
    "    'data/mega_train_embeddings',\n",
    "    'data/mega_train.csv'\n",
    ")\n",
    "dataset_val = ProtEmbeddingDataset(\n",
    "    'data/mega_val_embeddings',\n",
    "    'data/mega_val.csv'\n",
    ")\n",
    "\n",
    "loader_train = DataLoader(dataset_train, batch_size=1024, shuffle=True,  num_workers=4)\n",
    "loader_val   = DataLoader(dataset_val,   batch_size=512,  shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0a53664-4ce4-4203-a9ec-197f773ff330",
   "metadata": {},
   "source": [
    "\n",
    "class StabModel(L.LightningModule):\n",
    "    def __init__(self, input_dim=768, lr=1e-3):\n",
    "        super().__init__()\n",
    "        # Adding a hidden layer to actually use the ReLU activation\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, input_dim]\n",
    "        return self.model(x).squeeze(1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = self.loss_fn(preds, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a24535f0-dde1-439e-bba6-42ac864b79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchmetrics.regression import PearsonCorrCoef, SpearmanCorrCoef\n",
    "\n",
    "class StabModel(L.LightningModule):\n",
    "    def __init__(self, input_dim=768, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "         \n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.lr = lr\n",
    "\n",
    "        # Metrics\n",
    "        self.val_pearson = PearsonCorrCoef()\n",
    "        self.val_spearman = SpearmanCorrCoef()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = self.loss_fn(preds, y)\n",
    "        \n",
    "        # Print Train Loss to console/progress bar\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = self.loss_fn(preds, y)\n",
    "        \n",
    "        # Update correlation metrics\n",
    "        self.val_pearson(preds, y)\n",
    "        self.val_spearman(preds, y)\n",
    "        \n",
    "        # Print Val stats to console/progress bar\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_pear\", self.val_pearson, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_spear\", self.val_spearman, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "479ad72a-c4b5-4a2a-a1ac-ef85476f8458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/course/bc_NN/.venv/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type             | Params | Mode  | FLOPs\n",
      "------------------------------------------------------------------\n",
      "0 | model        | Sequential       | 197 K  | train | 0    \n",
      "1 | loss_fn      | MSELoss          | 0      | train | 0    \n",
      "2 | val_pearson  | PearsonCorrCoef  | 0      | train | 0    \n",
      "3 | val_spearman | SpearmanCorrCoef | 0      | train | 0    \n",
      "------------------------------------------------------------------\n",
      "197 K     Trainable params\n",
      "0         Non-trainable params\n",
      "197 K     Total params\n",
      "0.788     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb615bb9acc34ae1b1a5acaac1e03fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/course/bc_NN/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216e84ca56c74217bccdbb86f6a5cc88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181db15c663940c09d2794468222ae46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986ca29a31034bbaa9b2390c04abb6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "model = StabModel(lr = 1e-3)\n",
    "\n",
    "trainer = L.Trainer(devices =1, max_epochs= 2)\n",
    "trainer.fit(model, loader_train, loader_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ce5dd5e-278c-4f45-b504-f24bf15b150a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 199461), started 0:00:36 ago. (Use '!kill 199461' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a8df3ae63c4c090e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a8df3ae63c4c090e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/val_spear=0.221, train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743936cb-e739-4634-acda-b4c00c0faf29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
