{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa314390-6e6c-4896-8432-0fc8e7dcd7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import sklearn.metrics as skmetrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import lightning as L\n",
    "\n",
    "# Amino acid alphabet and encoding\n",
    "aa_alphabet = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "aa_to_int   = {aa: i for i, aa in enumerate(aa_alphabet)}\n",
    "\n",
    "class FlatMutationDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        # remove wild type rows\n",
    "        self.df = self.df[self.df.mut_type != 'wt'].reset_index(drop=True)\n",
    "        # extract wt and mut amino acids from mut_type string e.g. 'E1Q'\n",
    "        self.df['wt_aa']  = self.df['mut_type'].apply(lambda x: x[0])\n",
    "        self.df['mut_aa'] = self.df['mut_type'].apply(lambda x: x[-1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # one-hot encode wt and mutant amino acid\n",
    "        wt_oh  = torch.zeros(20)\n",
    "        mut_oh = torch.zeros(20)\n",
    "        wt_oh[aa_to_int[row['wt_aa']]]   = 1\n",
    "        mut_oh[aa_to_int[row['mut_aa']]] = 1\n",
    "        # concatenate to 40-dimensional input vector\n",
    "        x = torch.cat([wt_oh, mut_oh])\n",
    "        y = torch.tensor(row['ddG_ML'], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "# Load datasets\n",
    "dataset_train = FlatMutationDataset('data/mega_train.csv')\n",
    "dataset_val   = FlatMutationDataset('data/mega_val.csv')\n",
    "\n",
    "loader_train  = DataLoader(dataset_train, batch_size=256, shuffle=True,  num_workers=4)\n",
    "loader_val    = DataLoader(dataset_val,   batch_size=256, shuffle=False, num_workers=4)\n",
    "\n",
    "# quick sanity check\n",
    "print(\"Training samples:  \", len(dataset_train))\n",
    "print(\"Validation samples:\", len(dataset_val))\n",
    "x_sample, y_sample = dataset_train[0]\n",
    "print(\"Input shape:\", x_sample.shape)   # should be (40,)\n",
    "print(\"Label:\", y_sample)               # should be a flo\n",
    "\n",
    "# Data exploration\n",
    "train_df = pd.read_csv('data/mega_train.csv')\n",
    "train_df = train_df[train_df.mut_type != 'wt']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(train_df['ddG_ML'], bins=50)\n",
    "axes[0].set_xlabel('ddG_ML')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Training ddG distribution')\n",
    "\n",
    "# mutation type counts\n",
    "mut_counts = train_df['mut_type'].apply(lambda x: x[0] + '→' + x[-1])\n",
    "mut_counts.value_counts().head(20).plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Top 20 most common mutations')\n",
    "axes[1].set_xlabel('Mutation')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean ddG:\", train_df['ddG_ML'].mean())\n",
    "print(\"Std  ddG:\", train_df['ddG_ML'].std())\n",
    "print(\"Min  ddG:\", train_df['ddG_ML'].min())\n",
    "print(\"Max  ddG:\", train_df['ddG_ML'].max())\n",
    "\n",
    "# Model\n",
    "class MutationLinear(L.LightningModule):\n",
    "    def __init__(self, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        # single linear layer: 40 inputs → 1 output\n",
    "        self.linear  = nn.Linear(40, 1)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x).squeeze(1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss = self.loss_fn(self(x), y)\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss = self.loss_fn(self(x), y)\n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "\n",
    "# Train\n",
    "model   = MutationLinear(lr=1e-3)\n",
    "trainer = L.Trainer(devices=1, max_epochs=20)\n",
    "trainer.fit(model, loader_train, loader_val)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "preds = []\n",
    "all_y = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader_val:\n",
    "        x, y  = batch\n",
    "        y_hat = model(x)\n",
    "        preds.append(y_hat.detach().numpy())\n",
    "        all_y.append(y.detach().numpy())\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "all_y = np.concatenate(all_y)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.regplot(x=preds, y=all_y, scatter_kws={'alpha': 0.1})\n",
    "plt.xlabel(\"Predicted ddG\")\n",
    "plt.ylabel(\"Measured ddG\")\n",
    "plt.title(\"Linear model: predicted vs measured ddG\")\n",
    "plt.show()\n",
    "\n",
    "# metricsd-work\n",
    "print(\"RMSE:      \", skmetrics.mean_squared_error(all_y, preds))#, squared=False))\n",
    "print(\"Pearson r: \", scipy.stats.pearsonr(preds, all_y))\n",
    "print(\"Spearman r:\", scipy.stats.spearmanr(preds, all_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc7f75b-cf1c-4a7a-a796-3f8e739ba51c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
