{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f1ebf91-9250-417f-86ad-54ece7c8fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from transformers import AutoTokenizer, EsmModel\n",
    "import time\n",
    "import lightning as L\n",
    "import os\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import sklearn.metrics as skmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    \n",
    "class SequenceTransformer(L.LightningModule):\n",
    "    def __init__(self, lr=1e-3, d_model=64, nhead=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        \n",
    "        # project one-hot (20) to d_model dimensions\n",
    "        self.input_proj = nn.Linear(20, d_model)\n",
    "        \n",
    "        # transformer encoder\n",
    "        encoder_layer = nn.TraansformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=256,\n",
    "            dropout=0.1,\n",
    "            batch_first=True,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # output projection: d_model â†’ 20 (one ddG per possible mutation)\n",
    "        self.output_proj = nn.Linear(d_model, 20)\n",
    "        \n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (1, L, 20)\n",
    "        out = self.input_proj(x)      # (1, L, d_model)\n",
    "        out = self.transformer(out)   # (1, L, d_model)\n",
    "        out = self.output_proj(out)   # (1, L, 20)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x      = batch['sequence']   # (1, L, 20)\n",
    "        mask   = batch['mask']       # (1, L, 20)\n",
    "        target = batch['labels']     # (1, L, 20)\n",
    "        pred   = self(x)             # (1, L, 20)\n",
    "        loss   = self.loss_fn(pred[mask==1], target[mask==1])\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x      = batch['sequence']\n",
    "        mask   = batch['mask']\n",
    "        target = batch['labels']\n",
    "        pred   = self(x)\n",
    "        loss   = self.loss_fn(pred[mask==1], target[mask==1])\n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c914132-e04d-473e-872c-b6942bd77ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceData(Dataset):\n",
    "    def __init__(self, csv_file, label_col=\"ddG_ML\"):\n",
    "        self.df = pd.read_csv(csv_file, sep=\",\")\n",
    "        self.df = self.df[self.df.mut_type!=\"wt\"]\n",
    "        self.df[\"mutation_pos\"] = self.df[\"mut_type\"].apply(lambda x: int(x[1:-1])-1)\n",
    "        self.df[\"mutation_to\"] = self.df[\"mut_type\"].apply(lambda x: aa_to_int[x[-1]])\n",
    "        self.df = self.df.groupby(\"WT_name\").agg(list)\n",
    "        self.wt_names = self.df.index.values\n",
    "        self.encoded_seqs = {}\n",
    "        for wt_name in self.wt_names:\n",
    "            mut_row = self.df.loc[wt_name]\n",
    "            seq = mut_row[\"wt_seq\"][0]\n",
    "            self.encoded_seqs[wt_name] = one_hot_encode(seq)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wt_name = self.wt_names[idx]\n",
    "        mut_row = self.df.loc[wt_name]\n",
    "        sequence_encoding = self.encoded_seqs[wt_name]\n",
    "        mask = torch.zeros((1, len(sequence_encoding), 20))\n",
    "        target = torch.zeros((1, len(sequence_encoding), 20))\n",
    "        positions = torch.tensor(mut_row[\"mutation_pos\"])\n",
    "        amino_acids = torch.tensor(mut_row[\"mutation_to\"])\n",
    "        labels = torch.tensor(mut_row[self.label_col])\n",
    "        for i in range(len(sequence_encoding)):\n",
    "            mask[0,i,amino_acids[positions==i]] = 1\n",
    "            target[0,i,amino_acids[positions==i]] = labels[positions==i]\n",
    "        return {\"sequence\": sequence_encoding[None,:,:].float(), \"mask\": mask, \"labels\": target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4d944d-4e5e-4e09-a9fa-b073406ddaa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SequenceData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# use notebook 3's dataloader\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m dataset_train = \u001b[43mSequenceData\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mdata/mega_train.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m dataset_val   = SequenceData(\u001b[33m'\u001b[39m\u001b[33mdata/mega_val.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m loader_train  = DataLoader(dataset_train, batch_size=\u001b[32m1\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'SequenceData' is not defined"
     ]
    }
   ],
   "source": [
    "# use notebook 3's dataloader\n",
    "dataset_train = SequenceData('data/mega_train.csv')\n",
    "dataset_val   = SequenceData('data/mega_val.csv')\n",
    "loader_train  = DataLoader(dataset_train, batch_size=1, shuffle=True)\n",
    "loader_val    = DataLoader(dataset_val,   batch_size=1, shuffle=False)\n",
    "\n",
    "model   = SequenceTransformer(lr=1e-3, d_model=64, nhead=4, num_layers=2)\n",
    "trainer = L.Trainer(devices=1, max_epochs=20)\n",
    "trainer.fit(model, loader_train, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d14a68-ad7d-408f-bfd0-8dd61ce600be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
